{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense with adversarial training\n",
    "\n",
    "In this section we will use adversarial training to harden our CNN against adversarial examples. \n",
    "\n",
    "In adversarial training the dataset get \"augmented\" with adversarial examples that are correctly labeled. This way the network learns that such pertubations are possible and can adapt to them. \n",
    "\n",
    "We will be using the IBM Adversarial Robustness Toolbox in this exercise. It does offer a very easy to use implementation of adversarial training and bunch of other defenses. \n",
    "https://github.com/IBM/adversarial-robustness-toolbox\n",
    "\n",
    "\n",
    "We start out by importing most of the things we need. The `helpers` module contains a bunch of code that we have used in earlier exersices. They functions have been moved there to keep it shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of our imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "with warnings.catch_warnings():\n",
    "    import keras # keras is still using some deprectade code\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.attacks import BasicIterativeMethod, FastGradientMethod, CarliniWagnerL2\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from art.classifiers import KerasClassifier\n",
    "from helpers import load_mnist, exract_ones_and_zeroes, convert_to_keras_image_format, mnist_cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start out by loading the data, preparing it and training our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test)= load_mnist()\n",
    "\n",
    "# extract ones and zeroes\n",
    "x_train, y_train = exract_ones_and_zeroes( x_train, y_train )\n",
    "x_test, y_test = exract_ones_and_zeroes( x_test, y_test )\n",
    "\n",
    "# we need to bring the data in to a format that our cnn likes\n",
    "y_train = keras.utils.to_categorical( y_train, 2 )\n",
    "y_test = keras.utils.to_categorical( y_test, 2 )\n",
    "\n",
    "# convert it to a format keras can work with\n",
    "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
    "\n",
    "# need to some setup so everything gets excturted in the same tensorflow session\n",
    "session = tf.Session( )\n",
    "keras.backend.set_session( session )\n",
    "\n",
    "# get and train our cnn\n",
    "clf = mnist_cnn_model( x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know how robust our model is against an attack. To do this we are calculating the `empirical robustness` This is equivalent to computing the minimal perturbation that the attacker must introduce for a    successful attack. Paper link: https://arxiv.org/abs/1511.04599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.metrics import empirical_robustness\n",
    "\n",
    "# wrap the model an calculte emperical robustnees\n",
    "wrapper = KerasClassifier(clip_values=(0,1), model=clf)\n",
    "print( 'robustness of the undefended model', \n",
    "      empirical_robustness( wrapper, x_test, 'fgsm', {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an adversarial example and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an adversarial example with fgsm and plot it\n",
    "from art.attacks import FastGradientMethod\n",
    "fgsm = FastGradientMethod( wrapper )\n",
    "x_adv = fgsm.generate(x_test[0].reshape((1,28,28,1) ))\n",
    "print( 'class prediction for the adversarial sample:',\n",
    "       clf.predict( x_adv.reshape((1,28,28,1) ) ) \n",
    "     )\n",
    "plt.imshow( x_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
    "plt.axis( 'off' )\n",
    "plt.show( )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training\n",
    "\n",
    "We are getting new untrained model with the same architecture that we have been using so far. \n",
    "\n",
    "To use the adversarial training that comes with `art` we need to pass our wrapped model to and `AdversarialTrainer` instance. The `AdversarialTrainer` also needs an instance of the attack that will be used to create the adversarial exmaples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.defences import AdversarialTrainer\n",
    "\n",
    "# get a new untrained model and warp it\n",
    "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
    "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
    "# define the attack we are using\n",
    "fgsm = FastGradientMethod( defended_model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `AdversarialTrainer` instance. \n",
    "Train the model and evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the adversarial trainer and train the new network\n",
    "adversarial_tranier = AdversarialTrainer( defended_model, fgsm )\n",
    "adversarial_tranier.fit( x_train, y_train, batch_size=100, nb_epochs=2 )\n",
    "\n",
    "# evaluate how good our model is\n",
    "defended_model._model.evaluate( x_test,y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the `empirical robustness` for our now hopfully more robust model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the empiracal robustness\n",
    "print( 'robustness of the defended model', \n",
    "      empirical_robustness( defended_model, x_test[0:], 'fgsm', {}) )\n",
    "x_adv = fgsm.generate(x_test[0].reshape((1,28,28,1) ))\n",
    "print( 'class prediction for the adversarial sample:',\n",
    "       clf.predict( x_adv.reshape((1,28,28,1) ) ) \n",
    "     )\n",
    "plt.imshow( x_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
    "plt.axis( 'off' )\n",
    "plt.show( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
